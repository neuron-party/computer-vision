{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3233903e-8b31-4533-8e04-1431a7777f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision; torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd302dd-60cf-4383-8882-5a8f62c76e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_b_16 = models.vit_b_16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1845286-e5b3-4748-b220-569c5007aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_b_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdb02d52-eea7-4a3b-9314-d4629a8deff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = vit_b_16.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98d56354-a410-4a5d-89ad-7f8407e42268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['class_token', 'conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.mlp.linear_1.weight', 'encoder.layers.encoder_layer_0.mlp.linear_1.bias', 'encoder.layers.encoder_layer_0.mlp.linear_2.weight', 'encoder.layers.encoder_layer_0.mlp.linear_2.bias', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.mlp.linear_1.weight', 'encoder.layers.encoder_layer_1.mlp.linear_1.bias', 'encoder.layers.encoder_layer_1.mlp.linear_2.weight', 'encoder.layers.encoder_layer_1.mlp.linear_2.bias', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.mlp.linear_1.weight', 'encoder.layers.encoder_layer_2.mlp.linear_1.bias', 'encoder.layers.encoder_layer_2.mlp.linear_2.weight', 'encoder.layers.encoder_layer_2.mlp.linear_2.bias', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.mlp.linear_1.weight', 'encoder.layers.encoder_layer_3.mlp.linear_1.bias', 'encoder.layers.encoder_layer_3.mlp.linear_2.weight', 'encoder.layers.encoder_layer_3.mlp.linear_2.bias', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.mlp.linear_1.weight', 'encoder.layers.encoder_layer_4.mlp.linear_1.bias', 'encoder.layers.encoder_layer_4.mlp.linear_2.weight', 'encoder.layers.encoder_layer_4.mlp.linear_2.bias', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.mlp.linear_1.weight', 'encoder.layers.encoder_layer_5.mlp.linear_1.bias', 'encoder.layers.encoder_layer_5.mlp.linear_2.weight', 'encoder.layers.encoder_layer_5.mlp.linear_2.bias', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.mlp.linear_1.weight', 'encoder.layers.encoder_layer_6.mlp.linear_1.bias', 'encoder.layers.encoder_layer_6.mlp.linear_2.weight', 'encoder.layers.encoder_layer_6.mlp.linear_2.bias', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.mlp.linear_1.weight', 'encoder.layers.encoder_layer_7.mlp.linear_1.bias', 'encoder.layers.encoder_layer_7.mlp.linear_2.weight', 'encoder.layers.encoder_layer_7.mlp.linear_2.bias', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.mlp.linear_1.weight', 'encoder.layers.encoder_layer_8.mlp.linear_1.bias', 'encoder.layers.encoder_layer_8.mlp.linear_2.weight', 'encoder.layers.encoder_layer_8.mlp.linear_2.bias', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.mlp.linear_1.weight', 'encoder.layers.encoder_layer_9.mlp.linear_1.bias', 'encoder.layers.encoder_layer_9.mlp.linear_2.weight', 'encoder.layers.encoder_layer_9.mlp.linear_2.bias', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.mlp.linear_1.weight', 'encoder.layers.encoder_layer_10.mlp.linear_1.bias', 'encoder.layers.encoder_layer_10.mlp.linear_2.weight', 'encoder.layers.encoder_layer_10.mlp.linear_2.bias', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.mlp.linear_1.weight', 'encoder.layers.encoder_layer_11.mlp.linear_1.bias', 'encoder.layers.encoder_layer_11.mlp.linear_2.weight', 'encoder.layers.encoder_layer_11.mlp.linear_2.bias', 'encoder.ln.weight', 'encoder.ln.bias', 'heads.head.weight', 'heads.head.bias'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdaaf42f-50ea-49d7-9fe9-ff94818b35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finetune(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = vit_b_16\n",
    "        self.fc1 = nn.Linear(1000, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc1(self.vit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b03b2ea4-a0f9-4a55-8ee3-1f43e51b8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4bbeb36-2ce2-445f-9ea5-26788a71f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0b629e2-9bbc-4c33-bbaa-4adb2973daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['street', 'sea', 'mountain', 'glacier', 'forest', 'buildings']\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b22289ea-127c-4c03-9512-1f0ab79e6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels, image_size):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.dir = 'D:/Data/intel/seg_train'\n",
    "        \n",
    "        i = 0\n",
    "        for folder in os.listdir(self.dir):\n",
    "            label = i\n",
    "            for file in tqdm(os.listdir(os.path.join(self.dir, folder))):\n",
    "                img_path = os.path.join(os.path.join(self.dir, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, image_size)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = np.reshape(image, [3, 224, 224])\n",
    "                image = image / 255 #normalize\n",
    "                 \n",
    "                # Append the image and its corresponding label to the output\n",
    "                self.data.append(image)\n",
    "                self.labels.append(label)\n",
    "            i += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "540b942f-95e0-4004-9bc5-6d8689e9aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2191/2191 [00:02<00:00, 879.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2271/2271 [00:02<00:00, 830.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2404/2404 [00:02<00:00, 858.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2512/2512 [00:02<00:00, 841.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2274/2274 [00:03<00:00, 699.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2382/2382 [00:04<00:00, 477.57it/s]\n"
     ]
    }
   ],
   "source": [
    "data = Data(labels, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8009e32e-735e-4864-b023-9184d25ccba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = torch.utils.data.random_split(data, [11226, 2808])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e28f03f-3d41-4f6f-9ccb-bfb2db74d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=8)\n",
    "valloader = torch.utils.data.DataLoader(val, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1f4c42e-4853-47d8-82c2-735c2765c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1a1f91f-edae-4b3a-8af5-5b265ae8e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "356c7689-333c-4be4-88c7-1794011f17cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Finetune(\n",
       "  (vit): VisionTransformer(\n",
       "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (encoder): Encoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (layers): Sequential(\n",
       "        (encoder_layer_0): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_1): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_2): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_3): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_4): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_5): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_6): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_7): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_8): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_9): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_10): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_11): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "            (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (heads): Sequential(\n",
       "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=1000, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0340695-e737-4e32-844f-2ebcf9652f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "val_losses = []\n",
    "avg_training_losses = []\n",
    "avg_val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "371b9959-2c53-41fb-9e81-47a8265f1e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                              | 1/50 [04:19<3:31:57, 259.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.2645423412322998, Validation Loss: 1.1932920217514038 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                            | 2/50 [08:40<3:28:12, 260.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.2410553693771362, Validation Loss: 1.1740763187408447 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                           | 3/50 [13:04<3:25:16, 262.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.2205301523208618, Validation Loss: 1.1605725288391113 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                         | 4/50 [17:27<3:21:09, 262.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.203190565109253, Validation Loss: 1.1443004608154297 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                        | 5/50 [21:49<3:16:42, 262.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.185283899307251, Validation Loss: 1.1325994729995728 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                      | 6/50 [26:12<3:12:37, 262.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.1693981885910034, Validation Loss: 1.1203306913375854 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▏                                                                    | 7/50 [30:37<3:08:45, 263.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.1554336547851562, Validation Loss: 1.1089664697647095 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▊                                                                   | 8/50 [35:01<3:04:26, 263.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.143202543258667, Validation Loss: 1.1013617515563965 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▍                                                                 | 9/50 [39:26<3:00:21, 263.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.1318480968475342, Validation Loss: 1.0932217836380005 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▊                                                               | 10/50 [43:49<2:55:47, 263.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.1195884943008423, Validation Loss: 1.0928120613098145 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▍                                                             | 11/50 [48:14<2:51:33, 263.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.109753966331482, Validation Loss: 1.0864580869674683 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▉                                                            | 12/50 [52:37<2:47:05, 263.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.1002120971679688, Validation Loss: 1.079654574394226 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▌                                                          | 13/50 [57:01<2:42:42, 263.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0928471088409424, Validation Loss: 1.0746668577194214 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████▌                                                       | 14/50 [1:01:26<2:38:26, 264.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0863393545150757, Validation Loss: 1.0704747438430786 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████                                                      | 15/50 [1:05:48<2:33:49, 263.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0800368785858154, Validation Loss: 1.0671337842941284 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                    | 16/50 [1:10:13<2:29:33, 263.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.07313072681427, Validation Loss: 1.0620017051696777 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████▏                                                  | 17/50 [1:14:35<2:24:55, 263.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0669574737548828, Validation Loss: 1.058765172958374 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▋                                                 | 18/50 [1:18:59<2:20:32, 263.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0607738494873047, Validation Loss: 1.0535577535629272 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████▎                                               | 19/50 [1:23:23<2:16:17, 263.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0556838512420654, Validation Loss: 1.0511506795883179 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▊                                              | 20/50 [1:27:47<2:11:50, 263.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0516060590744019, Validation Loss: 1.0495400428771973 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▎                                            | 21/50 [1:32:14<2:07:59, 264.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0489012002944946, Validation Loss: 1.0477895736694336 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▉                                           | 22/50 [1:36:37<2:03:13, 264.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0461064577102661, Validation Loss: 1.0462812185287476 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████▍                                         | 23/50 [1:41:02<1:59:01, 264.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0429519414901733, Validation Loss: 1.0426106452941895 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████▉                                        | 24/50 [1:45:25<1:54:23, 263.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0396718978881836, Validation Loss: 1.0398199558258057 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▌                                      | 25/50 [1:49:48<1:49:53, 263.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0356175899505615, Validation Loss: 1.0382088422775269 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████                                     | 26/50 [1:54:14<1:45:48, 264.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0324761867523193, Validation Loss: 1.036446452140808 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████▌                                   | 27/50 [1:58:37<1:41:11, 263.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0300464630126953, Validation Loss: 1.0345816612243652 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████                                  | 28/50 [2:03:04<1:37:06, 264.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0280860662460327, Validation Loss: 1.0350706577301025 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████▋                                | 29/50 [2:07:31<1:32:55, 265.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.025603175163269, Validation Loss: 1.0360736846923828 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████▏                              | 30/50 [2:11:58<1:28:36, 265.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0249981880187988, Validation Loss: 1.0362187623977661 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████▋                             | 31/50 [2:16:23<1:24:07, 265.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0252360105514526, Validation Loss: 1.0382988452911377 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████████▎                           | 32/50 [2:20:48<1:19:40, 265.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0257233381271362, Validation Loss: 1.038991928100586 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████▊                          | 33/50 [2:25:13<1:15:12, 265.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0253336429595947, Validation Loss: 1.0378787517547607 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████▎                        | 34/50 [2:29:40<1:10:51, 265.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0248044729232788, Validation Loss: 1.037051796913147 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▉                       | 35/50 [2:34:05<1:06:26, 265.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.024530291557312, Validation Loss: 1.0362545251846313 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▍                     | 36/50 [2:38:31<1:01:57, 265.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.023606300354004, Validation Loss: 1.0348557233810425 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████████████████████████████████▍                    | 37/50 [2:42:58<57:38, 266.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0222042798995972, Validation Loss: 1.0352634191513062 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████                   | 38/50 [2:47:24<53:13, 266.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0216481685638428, Validation Loss: 1.0358150005340576 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████▌                 | 39/50 [2:51:53<48:56, 266.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0213596820831299, Validation Loss: 1.0345349311828613 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████▏               | 40/50 [2:56:19<44:25, 266.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.020513653755188, Validation Loss: 1.0340473651885986 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████▊              | 41/50 [3:00:45<39:58, 266.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0205434560775757, Validation Loss: 1.0332064628601074 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████▎            | 42/50 [3:05:11<35:30, 266.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0197829008102417, Validation Loss: 1.0323046445846558 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▉           | 43/50 [3:09:40<31:09, 267.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.018716812133789, Validation Loss: 1.0312464237213135 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 44/50 [3:14:07<26:43, 267.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0174875259399414, Validation Loss: 1.0301152467727661 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████        | 45/50 [3:18:36<22:17, 267.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0162664651870728, Validation Loss: 1.029544472694397 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████▋      | 46/50 [3:23:00<17:46, 266.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0150874853134155, Validation Loss: 1.028824806213379 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 47/50 [3:27:25<13:18, 266.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.01496160030365, Validation Loss: 1.0286056995391846 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 48/50 [3:31:49<08:51, 265.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0157384872436523, Validation Loss: 1.0294779539108276 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 49/50 [3:36:14<04:25, 265.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0161031484603882, Validation Loss: 1.0299352407455444 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 50/50 [3:40:38<00:00, 264.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Training Loss: 1.0161058902740479, Validation Loss: 1.0313620567321777 *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for e in tqdm(range(50)):\n",
    "    for x, y in trainloader:\n",
    "        torch.cuda.empty_cache()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x = x.float()\n",
    "        \n",
    "        # train step\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y)\n",
    "        t_l = l.detach().cpu().numpy()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_losses.append(t_l)\n",
    "    \n",
    "    # with torch.no_grad() but this doesnt really make that big of a difference\n",
    "    for i, j in valloader:\n",
    "        # no optim zero grad, step, l.backward\n",
    "        i, j = i.to(device), j.to(device)\n",
    "        i = i.float()\n",
    "        \n",
    "        y_pred = model(i)\n",
    "        ll = loss(y_pred, j)\n",
    "        v_l = ll.detach().cpu().numpy()\n",
    "        \n",
    "        val_losses.append(v_l)\n",
    "        \n",
    "    avg_training_losses.append(np.mean(training_losses))\n",
    "    avg_val_losses.append(np.mean(val_losses))\n",
    "        \n",
    "    print(f' *** Training Loss: {np.mean(training_losses)}, Validation Loss: {np.mean(val_losses)} *** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23793d09-f662-4ee3-8e71-d6a2595fe4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec8a5b69-6566-4d15-90e7-bc02dadd2d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x223769e1700>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_training_losses)\n",
    "plt.plot(avg_val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09d8db72-7d05-4ae4-80e1-cff24f341ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = [], []\n",
    "\n",
    "for x, y in valloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    x = x.float()\n",
    "    y_pred = model(x)\n",
    "    y_pred, y = y_pred.detach().cpu().numpy(), y.detach().cpu().numpy()\n",
    "    yes = np.argmax(y_pred, axis=1)\n",
    "    a.append(yes)\n",
    "    b.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c66a1a5-4ede-4c40-9d5e-831c18b0a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5544871794871795"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in zip(a, b):\n",
    "    for k, l in zip(i, j):\n",
    "        if k == l:\n",
    "            count += 1\n",
    "count/2808"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
